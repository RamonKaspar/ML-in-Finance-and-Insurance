{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f8b1dcf",
   "metadata": {},
   "source": [
    "**Write the names of all group members (max. 5 members)**:\n",
    "- Ramon, Kaspar\n",
    "- Cyrill, Stotz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd61e386-f037-4784-a966-d74f5aef180c",
   "metadata": {},
   "source": [
    "When submitting your work, please follow closely the template below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b87eda",
   "metadata": {},
   "source": [
    "# Exercise 1 (Poisson GLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fed2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing, model_selection, linear_model\n",
    "\n",
    "RANDOM_STATE = 69   # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1793f0",
   "metadata": {},
   "source": [
    "### Question 1.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83452882-ca86-4235-a079-9c67609ea94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names:  Index(['VehPower', 'VehAge', 'DrivAge', 'BonusMalus', 'VehBrand', 'VehGas',\n",
      "       'Density', 'Region', 'Exposure', 'ClaimNb'],\n",
      "      dtype='object')\n",
      "Number of Rows:  678007\n"
     ]
    }
   ],
   "source": [
    "# Read csv file `freMTPL2freq.csv` (e.g. use pandas)\n",
    "data_df = pd.read_csv('freMTPL2freq.csv', sep=';', decimal=',')\n",
    "print(\"Column Names: \", data_df.columns)\n",
    "print(\"Number of Rows: \", len(data_df))\n",
    "assert len(data_df) == 678007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7ccdf8d-76b7-4fb6-a83b-13232d2f7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process features\n",
    "\n",
    "def preprocess_features(df):\n",
    "    \"\"\"Feature Engineering\"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    df_processed['VehPower'] = np.log(df_processed['VehPower'])\n",
    "    df_processed['DrivAge'] = np.log(df_processed['DrivAge'])\n",
    "    df_processed['BonusMalus'] = np.log(df_processed['BonusMalus'])\n",
    "    df_processed['Density'] = np.log(df_processed['Density'])\n",
    "    \n",
    "    # Convert VehAge to categorical\n",
    "    def categorize_veh_age(age):\n",
    "        if age < 6:\n",
    "            return '0-6'\n",
    "        elif age < 13:\n",
    "            return '6-13'\n",
    "        else:\n",
    "            return '13+'\n",
    "        \n",
    "    df_processed['VehAge'] = df_processed['VehAge'].apply(categorize_veh_age)\n",
    "\n",
    "    return df_processed\n",
    "\n",
    "# Calculate claim frequency, i.e., the target variable y\n",
    "data_df['ClaimFreq'] = data_df['ClaimNb'] / data_df['Exposure']\n",
    "\n",
    "# Preprocess features\n",
    "data_processed_df = preprocess_features(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b164cba",
   "metadata": {},
   "source": [
    "### Question 1.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12ce70e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Claim Frequency: 0.11790710080746372\n",
      "Number of Claims: 26383\n",
      "Number of Policies without Claims: 653069 (96.32%)\n",
      "Number of NaNs: 0\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics about the data\n",
    "print(f\"Average Claim Frequency: {data_df['ClaimFreq'].mean()}\")\n",
    "print(f\"Number of Claims: {data_df['ClaimNb'].sum()}\")\n",
    "number_of_policies_without_claims = len(data_df[data_df['ClaimNb'] == 0])\n",
    "num_of_policies_without_claims_rel = 100*number_of_policies_without_claims / len(data_df)\n",
    "print(f\"Number of Policies without Claims: {number_of_policies_without_claims} ({num_of_policies_without_claims_rel:.2f}%)\")\n",
    "print(f\"Number of NaNs: {data_processed_df.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d7879",
   "metadata": {},
   "source": [
    "**COMMENT:** We can see that most policy holders have no claims at all (i.e., $96.32\\%$ of the policy holders have zero claims). So when we would model the problem as binary classification, we would have a very imbalanced dataset. Therefore, Poisson regression is a good choice here. \\\n",
    "Furthermore, we don't have any NaNs in the dataset, so we don't have to deal with missing values â€“ nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46481cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  Index(['VehPower', 'DrivAge', 'BonusMalus', 'Density', 'VehAge_0-6',\n",
      "       'VehAge_13+', 'VehAge_6-13', 'VehBrand_B1', 'VehBrand_B10',\n",
      "       'VehBrand_B11', 'VehBrand_B12', 'VehBrand_B13', 'VehBrand_B14',\n",
      "       'VehBrand_B2', 'VehBrand_B3', 'VehBrand_B4', 'VehBrand_B5',\n",
      "       'VehBrand_B6', 'VehGas_Diesel', 'VehGas_Regular', 'Region_R11',\n",
      "       'Region_R21', 'Region_R22', 'Region_R23', 'Region_R24', 'Region_R25',\n",
      "       'Region_R26', 'Region_R31', 'Region_R41', 'Region_R42', 'Region_R43',\n",
      "       'Region_R52', 'Region_R53', 'Region_R54', 'Region_R72', 'Region_R73',\n",
      "       'Region_R74', 'Region_R82', 'Region_R83', 'Region_R91', 'Region_R93',\n",
      "       'Region_R94'],\n",
      "      dtype='object')\n",
      "Number of Features:  42\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "X = data_processed_df.drop(['Exposure', 'ClaimNb', 'ClaimFreq'], axis=1)\n",
    "y = data_df['ClaimFreq']\n",
    "exposure = data_df['Exposure']\n",
    "\n",
    "X_train, X_test, y_train, y_test, exposure_train, exposure_test = model_selection.train_test_split(\n",
    "    X, y, exposure, test_size=0.1, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Separate features\n",
    "categorical_features = ['VehAge', 'VehBrand', 'VehGas', 'Region']\n",
    "numerical_features = ['VehPower', 'DrivAge', 'BonusMalus', 'Density']\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "# One-hot encode categorical features using the training data\n",
    "X_train = pd.get_dummies(X_train, columns=categorical_features)\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_features)\n",
    "\n",
    "print(\"Features: \", X_train.columns)\n",
    "print(\"Number of Features: \", len(X_train.columns))\n",
    "assert len(X_train.columns) == len(X_test.columns)  # Ensure that the test and train set have same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bc46cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Poisson GLM\n",
    "\n",
    "# NOTE: We choose alpha=0 (without regularization)\n",
    "poisson_reg = linear_model.PoissonRegressor(alpha=0)\n",
    "poisson_reg.fit(X_train, y_train, sample_weight=exposure_train)\n",
    "\n",
    "y_train_pred = poisson_reg.predict(X_train)\n",
    "y_test_pred = poisson_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6e18752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample Loss:\n",
      "---------------------------------\n",
      "MAE: 0.1876\n",
      "MAE (Weighted): 0.1377\n",
      "MSE: 3.7329\n",
      "MSE (Weighted): 0.2347\n",
      "Exposure-Weighted Poisson Deviance Loss: 0.4563\n",
      "Exposure-Weighted Poisson Deviance Loss (sklearn): 0.4563\n",
      "---------------------------------\n",
      "\n",
      "Out-of-sample Loss:\n",
      "---------------------------------\n",
      "MAE: 0.2010\n",
      "MAE (Weighted): 0.1387\n",
      "MSE: 6.5031\n",
      "MSE (Weighted): 0.2597\n",
      "Exposure-Weighted Poisson Deviance Loss: 0.4627\n",
      "Exposure-Weighted Poisson Deviance Loss (sklearn): 0.4627\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ramon\\anaconda3\\envs\\ml-env\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\ramon\\anaconda3\\envs\\ml-env\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Print MAE, MSE and loss on train and test data sets\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_poisson_deviance\n",
    "\n",
    "def calculate_loss(y_true, y_pred, exposure, print_results=True):\n",
    "    \"\"\"Calculates MAE, MSE and the exposure-weighted Poisson deviance loss.\"\"\"\n",
    "    # Mean Absolute Error (MAE) and Mean Squared Error (MSE)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mae_weighted = mean_absolute_error(y_true, y_pred, sample_weight=exposure)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mse_weighted = mean_squared_error(y_true, y_pred, sample_weight=exposure)\n",
    "    \n",
    "    # Calculate Poisson deviance loss (manually, and using sklearn built-in function)\n",
    "    y_true_log = np.where(y_true > 0, y_true * np.log(y_true), 0)\n",
    "    y_pred_log = np.where(y_pred > 0, y_true * np.log(y_pred), 0)\n",
    "    poisson_deviance = 2 * (y_pred - y_true - y_pred_log + y_true_log)\n",
    "    exp_weighted_poisson_loss = np.sum(exposure * poisson_deviance) / np.sum(exposure) if np.sum(exposure) > 0 else 0\n",
    "    \n",
    "    exp_weighted_poisson_loss_sklearn = mean_poisson_deviance(y_true, y_pred, sample_weight=exposure)\n",
    "    \n",
    "    if print_results:\n",
    "        print(\"---------------------------------\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(f\"MAE (Weighted): {mae_weighted:.4f}\")\n",
    "        print(f\"MSE: {mse:.4f}\")\n",
    "        print(f\"MSE (Weighted): {mse_weighted:.4f}\")\n",
    "        print(f\"Exposure-Weighted Poisson Deviance Loss: {exp_weighted_poisson_loss:.4f}\")\n",
    "        print(f\"Exposure-Weighted Poisson Deviance Loss (sklearn): {exp_weighted_poisson_loss_sklearn:.4f}\")\n",
    "        print(\"---------------------------------\")\n",
    "    return mae, mae_weighted, mse, mse_weighted, exp_weighted_poisson_loss\n",
    "\n",
    "\n",
    "# In-sample loss\n",
    "print(\"In-sample Loss:\")\n",
    "_ = calculate_loss(y_train, y_train_pred, exposure_train)\n",
    "\n",
    "# Out-of-sample loss\n",
    "print(\"\\nOut-of-sample Loss:\")\n",
    "_ = calculate_loss(y_test, y_test_pred, exposure_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d65003",
   "metadata": {},
   "source": [
    "**COMMENT:** From the small increase in the loss from the training to the test set, we can conclude that the model generalizes well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c6ffd9",
   "metadata": {},
   "source": [
    "# Exercise 2 (Poisson FNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17aa10f-12c9-4099-9658-f5c5cd80aa79",
   "metadata": {},
   "source": [
    "### Question 2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d70ea86-c63a-4c32-a636-de6959f35a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533fd342-036a-47bd-92e7-cf5d0803be6b",
   "metadata": {},
   "source": [
    "### Question 2.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42993cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Poisson feedforward neural network model\n",
    "\n",
    "# Print MAE, MSE and loss on train and test data sets\n",
    "\n",
    "# Make sure your model outperforms the Poisson GLM model of Question 1.b."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e13c13",
   "metadata": {},
   "source": [
    "# Exercise 3 (Tree-based methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395e7240",
   "metadata": {},
   "source": [
    "### Question 3.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b24141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a regression tree\n",
    "\n",
    "# Cross-validation\n",
    "\n",
    "# Print MAE, MSE and loss on train and test data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c7a083-b2f5-4917-830f-560c96dd876f",
   "metadata": {},
   "source": [
    "### Question 3.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb85291-ba3b-4edd-940c-d88192f338be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a random forest model\n",
    "\n",
    "# Cross-validation\n",
    "\n",
    "# Print MAE, MSE and loss on train and test data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4263e6",
   "metadata": {},
   "source": [
    "### Question 3.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee525e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement gradient boosted trees\n",
    "\n",
    "# Cross-validation\n",
    "\n",
    "# Print MAE, MSE and loss on train and test data sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
